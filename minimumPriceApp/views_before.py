"""
Django REST API for Excel file processing with Naver Shopping API price search
Supports card game price search and update functionality
"""

from rest_framework.decorators import api_view, permission_classes, parser_classes
from rest_framework.permissions import AllowAny
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework.response import Response
from rest_framework import status, serializers
import pandas as pd
import numpy as np
from django.http import HttpResponse, JsonResponse
from io import BytesIO
import os
import urllib.request
import urllib.parse
import json
import time
import re
import openpyxl
from openpyxl.styles import PatternFill
import logging
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
import tempfile
from openpyxl.utils import get_column_letter

# API Configuration
NAVER_CLIENT_ID = "S_iul25XJKSybg_fiSAc"
NAVER_CLIENT_SECRET = "_73PsEM4om"
PLUS_PRICE = 0  # Additional amount to add to lowest price
API_DELAY = 0.3  # Delay between API requests (seconds)

# Excel Processing Configuration
PRODUCT_NAME_COLUMN = 3  # D column (0-indexed)
PRICE_COLUMN = 5  # F column (0-indexed)
DATA_START_ROW = 6  # Row where actual data starts

# Color definitions for price differences
COLOR_FILLS = {
    'none': PatternFill(fill_type=None),
    'green': PatternFill(start_color="00FF00", end_color="00FF00", fill_type="solid"),
    'blue': PatternFill(start_color="0000FF", end_color="0000FF", fill_type="solid"),
    'yellow': PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid"),
    'red': PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")
}

COLOR_LEGEND = [
    ("ì´ˆë¡ìƒ‰", "1000ì› ì´í•˜", COLOR_FILLS['green']),
    ("íŒŒë‘ìƒ‰", "2000ì› ì´í•˜", COLOR_FILLS['blue']),
    ("ë…¸ë‘ìƒ‰", "3000ì› ì´í•˜", COLOR_FILLS['yellow']),
    ("ë¹¨ê°•ìƒ‰", "3000ì› ì´ˆê³¼", COLOR_FILLS['red'])
]


class ExcelDataSerializer(serializers.Serializer):
    """Custom serializer for Excel data with proper null handling"""
    
    def to_representation(self, instance):
        data = {}
        for key, value in instance.items():
            if pd.isna(value) or (isinstance(value, (int, float)) and np.isinf(value)):
                data[key] = None
            elif isinstance(value, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64)):
                data[key] = int(value)
            elif isinstance(value, (np.float16, np.float32, np.float64)):
                data[key] = None if (np.isnan(value) or np.isinf(value)) else float(value)
            else:
                data[key] = value
        return data


class CardGamePatternExtractor:
    """Card game pattern extraction and search keyword generation"""
    
    @staticmethod
    def extract_onepiece_info(product_name):
        """Extract One Piece card search information"""
        # ë§ê°€(ìŠˆí¼ íŒ¨ëŸ¬ë ) íŒ¨í„´ ì²´í¬ - ìµœìš°ì„  ì²˜ë¦¬
        if "ë§ê°€" in product_name:
            card_match = re.search(r'(OP|EB|ST)\d{2}-\d{3}', product_name)
            if card_match:
                card_number = card_match.group()
                return f"ë§ê°€ {card_number}"
            else:
                return None
        
        # SP- íŒ¨í„´ ì²´í¬ (ëª¨ë‘ ìŠ¤í˜ì…œ ì¹´ë“œë¡œ ì²˜ë¦¬)
        sp_pattern = re.search(r'\bSP-(SP|SEC|R|SR|C|L|U|UC)\b', product_name)
        if sp_pattern:
            # ì¹´ë“œ ë²ˆí˜¸ ì¶”ì¶œ
            card_match = re.search(r'(OP|EB|ST)\d{2}-\d{3}', product_name)
            if card_match:
                card_number = card_match.group()
                return f"SP {card_number}"
            else:
                return None
        
        # P- ë ˆì–´ë„ íŒ¨í„´ ì²´í¬ (íŒ¨ëŸ¬ë )
        has_p_rarity = bool(re.search(r'\bP-(SEC|R|SR|C|L|U)\b', product_name))
        
        # ì¹´ë“œ ë²ˆí˜¸ íŒ¨í„´ ì°¾ê¸°
        card_patterns = [
            (r'(OP|EB|ST)\d{2}-\d{3}', 'standard'),  # ì¼ë°˜ ì¹´ë“œ
            (r'P-\d{3}', 'promo')  # í”„ë¡œëª¨ ì¹´ë“œ
        ]
        
        for pattern, card_type in card_patterns:
            match = re.search(pattern, product_name)
            if match:
                card_number = match.group()
                
                if card_type == 'promo':
                    return f"ì›í”¼ìŠ¤ {card_number}"
                elif has_p_rarity:
                    return f"íŒ¨ëŸ¬ë  {card_number}"
                elif card_number.startswith('ST'):
                    return f"ì›í”¼ìŠ¤ {card_number}"
                else:
                    return card_number
        
        # "ì›í”¼ìŠ¤"ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ì¶”ê°€ ê²€ìƒ‰
        if product_name.startswith("ì›í”¼ìŠ¤"):
            other_patterns = [
                (r'OP\d{2}-\d{3}', 'normal'),
                (r'(ST|EB|PR)\d{2}-\d{3}', 'special'),
                (r'P-\d{3}', 'promo')
            ]
            
            for pattern, ptype in other_patterns:
                match = re.search(pattern, product_name)
                if match:
                    card_number = match.group()
                    
                    if ptype == 'promo' or card_number.startswith('ST'):
                        result = f"ì›í”¼ìŠ¤ {card_number}"
                    elif has_p_rarity:
                        result = f"íŒ¨ëŸ¬ë  {card_number}"
                    else:
                        result = card_number
                    
                    return result
            
            # ë“±ê¸‰ íŒ¨í„´ ê²€ìƒ‰
            grade_match = re.search(r'(SR|R|C|L|SEC)\s+(OP|ST|EB|PR)\d{2}-\d{3}', product_name)
            if grade_match:
                card_number = grade_match.group(2)
                
                if has_p_rarity:
                    result = f"íŒ¨ëŸ¬ë  {card_number}"
                elif card_number.startswith('ST'):
                    result = f"ì›í”¼ìŠ¤ {card_number}"
                else:
                    result = card_number
                
                return result
        
        return None
    
    @staticmethod
    def extract_digimon_info(product_name):
        """Extract Digimon card search information"""
        # ìƒˆë¡œìš´ í˜•ì‹: "ë””ì§€ëª¬ì¹´ë“œ"ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if not product_name.startswith("ë””ì§€ëª¬ì¹´ë“œ"):
            return None
        
        # í¬ì†Œ/íŒ¨ëŸ¬ë  ì—¬ë¶€ í™•ì¸
        has_rare = "í¬ì†Œ" in product_name
        has_parallel = "íŒ¨ëŸ¬ë " in product_name
        
        # ì¼ë°˜ ì¹´ë“œ íŒ¨í„´
        card_match = re.search(r'(EX|BT|ST|RB|LM)\d{1,2}-\d{2,3}', product_name)
        if card_match:
            card_number = card_match.group()
            
            # ê²°ê³¼ ê²°ì •
            is_st_card = card_number.startswith('ST')
            prefix = ""
            
            if has_rare:
                prefix = "í¬ì†Œ "
            elif has_parallel:
                prefix = "íŒ¨ëŸ¬ë  "
            
            if is_st_card:
                result = f"{prefix}ë””ì§€ëª¬ {card_number}"
            else:
                result = f"{prefix}{card_number}" if prefix else card_number
            
            return result.strip()
        
        # í”„ë¡œëª¨ ì¹´ë“œ íŒ¨í„´
        promo_match = re.search(r'P-\d{3}', product_name)
        if promo_match:
            card_number = promo_match.group()
            prefix = "í¬ì†Œ " if has_rare else ("íŒ¨ëŸ¬ë  " if has_parallel else "")
            result = f"{prefix}ë””ì§€ëª¬ {card_number}"
            return result.strip()
        
        return None
    
    @staticmethod
    def extract_pokemon_info(product_name):
        """Extract Pokemon card search information"""
        if not product_name.startswith("í¬ì¼“ëª¬"):
            return None, None, None
        
        # í”„ë¡œëª¨ ì¹´ë“œ í™•ì¸
        promo_match = re.search(r'P-\d{3}', product_name)
        if promo_match:
            return f"í¬ì¼“ëª¬ {promo_match.group()}", None, None
        
        # ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„ (ë§ˆì§€ë§‰ ë‹¨ì–´=í™•ì¥íŒ© ì œì™¸)
        words = product_name.split()
        search_text = " ".join(words[:-1]) if len(words) > 1 else product_name
        last_word = words[-1] if len(words) > 1 else ""
        
        # ë ˆì–´ë„ ì¶”ì¶œ - SSR ì¶”ê°€!
        rarity_pattern = r'\b(UR|SSR|SR|RR|RRR|CHR|CSR|BWR|AR|SAR|HR|R|U|C|ëª¬ìŠ¤í„°ë³¼|ë§ˆìŠ¤í„°ë³¼|ì´ë¡œì¹˜)\b'
        rarity_match = re.search(rarity_pattern, search_text)
        rarity = rarity_match.group(1) if rarity_match else None
        
        # í¬ì¼“ëª¬ ì´ë¦„ ì¶”ì¶œ (ë ˆì–´ë„ ì œê±°)
        temp_name = search_text
        if rarity:
            rarity_index = temp_name.find(rarity)
            if rarity_index != -1:
                temp_name = temp_name[:rarity_index].strip()
        
        # íŠ¹ìˆ˜ íŒ¨í„´ í™•ì¸
        patterns = {
            'vmax': r'\b[ê°€-í£A-Za-z\s]+(?:VMAX|Vmax|vmax)\b',
            'vstar': r'\b[ê°€-í£A-Za-z\s]+(?:VStar|vstar|VSTAR)\b',
            'ex': r'\b[ê°€-í£A-Za-z\s]+ex\b',
            'v': r'\b[ê°€-í£A-Za-z\s]+V\b(?!\s*(?:MAX|max|Star|star))'
        }
        
        detected_patterns = {name: bool(re.search(pattern, temp_name, re.IGNORECASE)) 
                            for name, pattern in patterns.items()}
        
        # í¬ì¼“ëª¬ ì´ë¦„ ì¶”ì¶œ
        pokemon_name = None
        extraction_rules = [
            ('vmax', r'í¬ì¼“ëª¬ì¹´ë“œ\s+(.+?)\s*(?:VMAX|Vmax|vmax)'),
            ('vstar', r'í¬ì¼“ëª¬ì¹´ë“œ\s+(.+?)\s*(?:VStar|vstar|VSTAR)'),
            ('ex', r'í¬ì¼“ëª¬ì¹´ë“œ\s+(.+?ex)'),
            ('v', r'í¬ì¼“ëª¬ì¹´ë“œ\s+(.+?)\s*V\b(?!\s*(?:MAX|max|Star|star))'),
            (None, r'í¬ì¼“ëª¬ì¹´ë“œ\s+(.+)')
        ]
        
        for pattern_name, regex in extraction_rules:
            if pattern_name is None or detected_patterns.get(pattern_name, False):
                name_match = re.search(regex, temp_name, re.IGNORECASE)
                if name_match:
                    pokemon_name = name_match.group(1).strip()
                    break
        
        return product_name, rarity, pokemon_name
    
    @staticmethod
    def extract_search_info(product_name):
        """Extract search information from product name (unified function)"""
        # Try Digimon first (most specific pattern)
        digimon_result = CardGamePatternExtractor.extract_digimon_info(product_name)
        if digimon_result:
            return digimon_result, "ë””ì§€ëª¬", None
        
        # Try One Piece
        onepiece_result = CardGamePatternExtractor.extract_onepiece_info(product_name)
        if onepiece_result:
            return onepiece_result, "ì›í”¼ìŠ¤", None
        
        # Try Pokemon
        pokemon_search, pokemon_rarity, pokemon_name = CardGamePatternExtractor.extract_pokemon_info(product_name)
        if pokemon_search:
            return pokemon_search, "í¬ì¼“ëª¬", (pokemon_rarity, pokemon_name)
        
        return None, None, None


class NaverShoppingAPI:
    """Naver Shopping API client"""
    
    @staticmethod
    def search(search_name):
        """Search Naver Shopping API"""
        try:
            enc_text = urllib.parse.quote(search_name)
            url = f"https://openapi.naver.com/v1/search/shop?query={enc_text}&sort=sim&exclude=used:rental:cbshop&display=20"
            
            request = urllib.request.Request(url)
            request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            
            response = urllib.request.urlopen(request)
            if response.getcode() == 200:
                result = json.loads(response.read())
                return result.get('items', [])
            else:
                logging.error("API request failed")
                return []
        except Exception as e:
            logging.error(f"API exception: {e}")
            return []


class ItemFilter:
    """Filter API search results based on card game rules"""
    
    @staticmethod
    def check_item_filters(title, mall_name, card_type, card_number,
                          is_parallel, is_rare, is_special_day, is_special,
                          is_super_parallel, price,
                          required_rarity, required_pokemon_name):
        """ì•„ì´í…œ í•„í„°ë§ ì²´í¬ (í†µê³¼ ì—¬ë¶€ì™€ ë¡œê·¸ ë©”ì‹œì§€ ë°˜í™˜)"""
        
        # ì œì™¸ íŒë§¤ì²˜
        if mall_name in ["í™”ì„±ìŠ¤í† ì–´-TCG-", "ë„¤ì´ë²„", "ì¿ íŒ¡"]:
            return False, f"âŒ ì œì™¸: {mall_name}"
        
        # ì¼ë³¸íŒ ì œì™¸
        if any(keyword in title for keyword in ['ì¼ë³¸', 'ì¼ë³¸íŒ', 'JP', 'JPN', 'ì¼íŒ']):
            return False, "âŒ ì œì™¸: ì¼ë³¸íŒ"
        
        # ì›í”¼ìŠ¤/ë””ì§€ëª¬ì¹´ë“œ ë²ˆí˜¸ ë§¤ì¹­
        if card_type in ["ì›í”¼ìŠ¤", "ë””ì§€ëª¬"] and card_number:
            if card_number not in title:
                return False, f"âŒ ì œì™¸: ì¹´ë“œë²ˆí˜¸ '{card_number}' ë¶ˆì¼ì¹˜"
        
        # ì›í”¼ìŠ¤ ìŠˆí¼ íŒ¨ëŸ¬ë (ë§ê°€) í‚¤ì›Œë“œ í™•ì¸
        if card_type == "ì›í”¼ìŠ¤" and is_super_parallel:
            super_parallel_keywords = ['ìŠˆí¼ íŒ¨ëŸ¬ë ', 'ìŠˆí¼íŒ¨ëŸ¬ë ', 'ìŠˆí¼íŒŒë¼ë ', 'ìŠˆí¼ íŒŒë¼ë ']
            manga_keywords = ['ë§ê°€', 'MANGA', 'manga']
            
            # ìŠˆí¼ íŒ¨ëŸ¬ë  í‚¤ì›Œë“œ í™•ì¸
            has_super_parallel = any(kw in title for kw in super_parallel_keywords)
            # ë§ê°€ í‚¤ì›Œë“œ í™•ì¸
            has_manga = any(kw in title for kw in manga_keywords)
            
            # ë‘ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ì•¼ í•¨
            if not (has_super_parallel or has_manga):
                return False, "âŒ ì œì™¸: ìŠˆí¼ íŒ¨ëŸ¬ë  ë˜ëŠ” ë§ê°€ í‚¤ì›Œë“œ ì—†ìŒ"
            
            # ê°€ê²© ì²´í¬: 200,000ì› ë¯¸ë§Œ ì œì™¸
            if price < 200000:
                return False, f"âŒ ì œì™¸: ê°€ê²© {int(price)}ì› (20ë§Œì› ë¯¸ë§Œ)"
            
            matched_keywords = []
            if has_super_parallel:
                matched_keywords.append("ìŠˆí¼ íŒ¨ëŸ¬ë ")
            if has_manga:
                matched_keywords.append("ë§ê°€")
            
            logging.info(f"âœ… ìŠˆí¼ íŒ¨ëŸ¬ë (ë§ê°€) í‚¤ì›Œë“œ ë§¤ì¹­ ì„±ê³µ ({', '.join(matched_keywords)}) (ê°€ê²©: {int(price)}ì›)")
        
        # ì›í”¼ìŠ¤ ìŠ¤í˜ì…œ í‚¤ì›Œë“œ í™•ì¸
        elif card_type == "ì›í”¼ìŠ¤" and is_special:
            special_keywords = ['ìŠ¤í˜ì…œ', 'SP']
            matched_keyword = next((kw for kw in special_keywords if kw in title), None)
            if not matched_keyword:
                return False, "âŒ ì œì™¸: ìŠ¤í˜ì…œ í‚¤ì›Œë“œ ì—†ìŒ"
        
        # ì›í”¼ìŠ¤ íŒ¨ëŸ¬ë  í‚¤ì›Œë“œ í™•ì¸
        elif card_type == "ì›í”¼ìŠ¤" and is_parallel:
            parallel_keywords = ['íŒ¨ëŸ¬ë ', 'ë‹¤ë¥¸', 'íŒ¨ë ˆ', 'Pì‹œí¬ë¦¿ë ˆì–´', 'í˜ëŸ¬ëŸ´', 'íŒ¨ëŸ¬ëŸ´', 'í˜ëŸ¬ë ', 'í˜ë ˆ']
            matched_keyword = next((kw for kw in parallel_keywords if kw in title), None)
            if not matched_keyword:
                return False, "âŒ ì œì™¸: íŒ¨ëŸ¬ë  í‚¤ì›Œë“œ ì—†ìŒ"
        
        # ë””ì§€ëª¬ í¬ì†Œ/íŒ¨ëŸ¬ë  í‚¤ì›Œë“œ í™•ì¸
        elif card_type == "ë””ì§€ëª¬":
            if is_rare and "í¬ì†Œ" not in title:
                return False, "âŒ ì œì™¸: í¬ì†Œ í‚¤ì›Œë“œ ì—†ìŒ"
            
            if is_parallel and "íŒ¨ëŸ¬ë " not in title:
                return False, "âŒ ì œì™¸: íŒ¨ëŸ¬ë  í‚¤ì›Œë“œ ì—†ìŒ"
        
        # í¬ì¼“ëª¬ì¹´ë“œ ì¡°ê±´ í™•ì¸
        elif card_type == "í¬ì¼“ëª¬":
            if is_special_day and "íŠ¹ì¼" not in title:
                return False, "âŒ ì œì™¸: íŠ¹ì¼ í‚¤ì›Œë“œ ì—†ìŒ"
            
            # í¬ì¼“ëª¬ ì´ë¦„ ë§¤ì¹­
            if required_pokemon_name:
                clean_title = re.sub(r'<[^>]+>', '', title)
                
                # ë„ì–´ì“°ê¸° ì œê±° ë§¤ì¹­
                required_name_no_space = re.sub(r'\s+', '', required_pokemon_name)
                title_no_space = re.sub(r'\s+', '', clean_title)
                
                if required_name_no_space.lower() in title_no_space.lower():
                    pass  # ë§¤ì¹­ ì„±ê³µ
                else:
                    # ê°œë³„ ë‹¨ì–´ ë§¤ì¹­
                    required_words = [word for word in required_pokemon_name.split() 
                                    if word.lower() not in ['ex', 'v', 'vmax', 'vstar']]
                    
                    word_matches = sum(1 for word in required_words if word.lower() in clean_title.lower())
                    
                    if word_matches != len(required_words) or len(required_words) == 0:
                        return False, f"âŒ ê°œë³„ ë‹¨ì–´ ë§¤ì¹­ ì‹¤íŒ¨ ({word_matches}/{len(required_words)})"
            
            # ë ˆì–´ë„ ë§¤ì¹­
            if required_rarity:
                clean_title = re.sub(r'<[^>]+>', '', title)
                
                if required_rarity not in clean_title:
                    return False, f"âŒ ì œì™¸: ë ˆì–´ë„ '{required_rarity}' ë¯¸í¬í•¨"
        
        return True, "âœ… í†µê³¼: í•„í„°ë§ ì¡°ê±´ ë§Œì¡±"
    
    @staticmethod
    def filter_api_results(items, search_name, card_type, pokemon_info=None):
        """API ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§"""
        min_price = None
        valid_items_count = 0
        filter_match_info = "ì—†ìŒ"
        
        # ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •
        is_super_parallel = "ë§ê°€" in search_name  # ë§ê°€ í‚¤ì›Œë“œë¡œ ì²´í¬
        is_parallel = "íŒ¨ëŸ¬ë " in search_name and not is_super_parallel
        is_rare = "í¬ì†Œ" in search_name
        is_special_day = "íŠ¹ì¼" in search_name
        is_special = "SP" in search_name and not is_super_parallel
        
        # ì¹´ë“œë³„ ê¸°ë³¸ í•„í„° ì •ë³´
        if card_type == "ì›í”¼ìŠ¤":
            if is_super_parallel:
                filter_match_info = "ìŠˆí¼íŒ¨ëŸ¬ë (ë§ê°€)ê²€ìƒ‰"
            elif is_special:
                filter_match_info = "ìŠ¤í˜ì…œê²€ìƒ‰"
            elif is_parallel:
                filter_match_info = "íŒ¨ëŸ¬ë ê²€ìƒ‰"
            else:
                filter_match_info = "ì¼ë°˜ê²€ìƒ‰"
        elif card_type == "ë””ì§€ëª¬":
            filter_match_info = "í¬ì†Œê²€ìƒ‰" if is_rare else ("íŒ¨ëŸ¬ë ê²€ìƒ‰" if is_parallel else "ì¼ë°˜ê²€ìƒ‰")
        elif card_type == "í¬ì¼“ëª¬":
            filter_match_info = "í•„í„°ì—†ìŒ"
        
        # ì¹´ë“œ ë²ˆí˜¸ ì¶”ì¶œ
        card_number = None
        if card_type in ["ì›í”¼ìŠ¤", "ë””ì§€ëª¬"]:
            pattern = r'(OP|ST|EB|PR)\d{2}-\d{3}' if card_type == "ì›í”¼ìŠ¤" else r'(EX|BT|ST|RB|LM)\d{1,2}-\d{3}'
            card_match = re.search(pattern, search_name)
            card_number = card_match.group() if card_match else None
        
        # í¬ì¼“ëª¬ì¹´ë“œ ì •ë³´
        required_rarity, required_pokemon_name = pokemon_info or (None, None)
        
        # ì•„ì´í…œ í•„í„°ë§
        for item in items:
            title = item['title']
            price = float(item['lprice'])
            mall_name = item.get('mallName', '')
            
            # í•„í„° ì²´í¬
            passed, log_msg = ItemFilter.check_item_filters(
                title, mall_name, card_type, card_number,
                is_parallel, is_rare, is_special_day, is_special,
                is_super_parallel, price,
                required_rarity, required_pokemon_name
            )
            
            if not passed:
                continue
            
            # í†µê³¼í•œ ìƒí’ˆ
            valid_items_count += 1
            
            # ìµœì €ê°€ ì—…ë°ì´íŠ¸
            if min_price is None or price < min_price:
                min_price = price
                
                # í¬ì¼“ëª¬ì¹´ë“œ í•„í„° ì •ë³´ ì—…ë°ì´íŠ¸
                if card_type == "í¬ì¼“ëª¬":
                    if required_pokemon_name and required_rarity:
                        filter_match_info = "í¬ì¼“ëª¬ëª…+ë ˆì–´ë„"
                    elif required_pokemon_name:
                        filter_match_info = "í¬ì¼“ëª¬ëª…ë§Œ"
                    elif required_rarity:
                        filter_match_info = "ë ˆì–´ë„ë§Œ"
                    else:
                        filter_match_info = "í•„í„°ì—†ìŒ"
        
        return min_price, valid_items_count, filter_match_info


class PriceProcessor:
    """Process price updates for card games"""
    
    @staticmethod
    def process_price_update(product_name, original_price):
        """ê°€ê²© ì—…ë°ì´íŠ¸ ì²˜ë¦¬"""
        search_name, card_type, pokemon_info = CardGamePatternExtractor.extract_search_info(product_name)
        
        if not search_name:
            logging.info(f"{product_name} : {int(original_price)} (ê²€ìƒ‰ íŒ¨í„´ ì—†ìŒ)")
            return original_price, 0, "ë¯¸í™•ì¸", "íŒ¨í„´ì—†ìŒ", "íŒ¨í„´ì—†ìŒ", 0
        
        # API ê²€ìƒ‰
        items = NaverShoppingAPI.search(search_name)
        min_price, valid_items_count, filter_match_info = ItemFilter.filter_api_results(
            items, search_name, card_type, pokemon_info
        )
        
        # ê°€ê²© ê³„ì‚°
        new_price = (min_price + PLUS_PRICE) if min_price is not None else original_price
        price_diff = int(new_price - original_price)
        
        # ìƒì„¸ ë¡œê¹…
        if abs(price_diff) > 0:
            if card_type == "í¬ì¼“ëª¬" and pokemon_info:
                rarity, pokemon_name = pokemon_info
                info_text = f" (í¬ì¼“ëª¬: {pokemon_name or 'ì—†ìŒ'}"
                if rarity:
                    info_text += f", ë ˆì–´ë„: {rarity}"
                info_text += f", í•„í„°: {filter_match_info})"
                logging.info(f"{product_name} : {int(original_price)} â†’ {int(new_price)} ({price_diff:+}ì›) [{card_type}ì¹´ë“œ ì „ì²´ ê²€ìƒ‰{info_text}]")
            else:
                logging.info(f"{product_name} : {int(original_price)} â†’ {int(new_price)} ({price_diff:+}ì›) [{card_type}ì¹´ë“œ ê²€ìƒ‰ì–´: {search_name}]")
        else:
            if card_type == "í¬ì¼“ëª¬" and pokemon_info:
                rarity, pokemon_name = pokemon_info
                info_text = f" (í¬ì¼“ëª¬: {pokemon_name or 'ì—†ìŒ'}"
                if rarity:
                    info_text += f", ë ˆì–´ë„: {rarity}"
                info_text += f", í•„í„°: {filter_match_info})"
                logging.info(f"{product_name} : {int(original_price)} (ë³€ê²½ì—†ìŒ) [{card_type}ì¹´ë“œ ì „ì²´ ê²€ìƒ‰{info_text}]")
            else:
                logging.info(f"{product_name} : {int(original_price)} (ë³€ê²½ì—†ìŒ) [{card_type}ì¹´ë“œ ê²€ìƒ‰ì–´: {search_name}]")
        
        logging.info("-" * 60)
        
        time.sleep(API_DELAY)  # API ìš”ì²­ ì œí•œ ë°©ì§€
        return new_price, price_diff, card_type, filter_match_info, search_name, valid_items_count
    
    @staticmethod
    def get_fill_color(original_price, new_price):
        """ê°€ê²© ì°¨ì´ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •"""
        if abs(original_price - new_price) < 0.01:
            return COLOR_FILLS['none']
        
        price_diff = abs(new_price - original_price)
        
        if price_diff <= 1000:
            return COLOR_FILLS['green']
        elif price_diff <= 2000:
            return COLOR_FILLS['blue']
        elif price_diff <= 3000:
            return COLOR_FILLS['yellow']
        else:
            return COLOR_FILLS['red']


# ==================== API Endpoints ====================

# ë¡œê¹… ì„¤ì • - ì½˜ì†”ì—ë„ ì¶œë ¥ë˜ë„ë¡ ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(message)s')  # ì‹¬í”Œí•œ í¬ë§·
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

@api_view(['POST'])
@permission_classes([AllowAny])
@parser_classes([MultiPartParser, FormParser])
def upload_excel(request):
    """
    Upload Excel file and extract data
    
    Expected file format:
    - D column: Product names (ìƒí’ˆëª…)
    - F column: Prices (ê°€ê²©)
    - Data starts from row 6
    """
    if 'file' not in request.FILES:
        return Response({'error': 'No file provided'}, status=status.HTTP_400_BAD_REQUEST)
    
    excel_file = request.FILES['file']
    
    # Validate file extension
    if not excel_file.name.endswith(('.xlsx', '.xls')):
        return Response({'error': 'Invalid file format. Please upload .xlsx or .xls file'}, 
                       status=status.HTTP_400_BAD_REQUEST)
    
    try:
        # Read Excel file
        df = pd.read_excel(excel_file, header=None)
        
        # Extract relevant columns (D=3, F=5, 0-indexed)
        # Get all rows starting from index 5 (6th row in Excel, accounting for 0-indexing)
        data_rows = []
        for idx in range(DATA_START_ROW - 1, len(df)):  # -1 for 0-indexing
            product_name = df.iloc[idx, PRODUCT_NAME_COLUMN]
            price = df.iloc[idx, PRICE_COLUMN]
            
            # Skip if both values are NaN
            if pd.isna(product_name) and pd.isna(price):
                continue
            
            data_rows.append({
                'excelRow': idx + 1,  # Convert to 1-indexed Excel row number
                'productName': None if pd.isna(product_name) else str(product_name),
                'price': None if pd.isna(price) else float(price)
            })
        
        # Serialize data properly handling NaN/None values
        serializer = ExcelDataSerializer(data_rows, many=True)
        
        return Response({
            'message': 'File uploaded successfully',
            'data': serializer.data,
            'totalRows': len(data_rows)
        }, status=status.HTTP_200_OK)
        
    except Exception as e:
        return Response({'error': f'Failed to process file: {str(e)}'}, 
                       status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST'])
@permission_classes([AllowAny])
def search_prices(request):
    """
    Search prices for card game products using Naver Shopping API
    
    Request body:
    {
        "items": [
            {"productName": "string", "currentPrice": float},
            ...
        ]
    }
    
    Response:
    {
        "results": [
            {
                "productName": "string",
                "currentPrice": float,
                "newPrice": float,
                "priceDiff": int,
                "cardType": "string",
                "filterInfo": "string",
                "searchKeyword": "string",
                "validItemsCount": int
            },
            ...
        ]
    }
    """
    try:
        items = request.data.get('items', [])
        
        if not items:
            return Response({'error': 'No items provided'}, status=status.HTTP_400_BAD_REQUEST)
        
        # ì‹œì‘ ë¡œê·¸
        logging.info("=" * 80)
        logging.info("ğŸš€ ì¹´ë“œ ìµœì €ê°€ ê²€ìƒ‰ ì‹œì‘")
        logging.info("=" * 80)
        logging.info(f"ì²˜ë¦¬í•  ìƒí’ˆ ìˆ˜: {len(items)}ê°œ")
        logging.info(f"í˜„ì¬ ìµœì €ê°€ì—ì„œ {PLUS_PRICE}ì› ì¶”ê°€ë©ë‹ˆë‹¤.\n")
        
        results = []
        
        for idx, item in enumerate(items, 1):
            product_name = item.get('productName')
            current_price = item.get('currentPrice', 0)
            
            if not product_name:
                continue
            
            logging.info(f"[{idx}/{len(items)}] ì²˜ë¦¬ ì¤‘...")
            
            try:
                new_price, price_diff, card_type, filter_info, search_keyword, valid_count = \
                    PriceProcessor.process_price_update(product_name, float(current_price))
                
                results.append({
                    'productName': product_name,
                    'currentPrice': current_price,
                    'newPrice': new_price,
                    'priceDiff': price_diff,
                    'cardType': card_type,
                    'filterInfo': filter_info,
                    'searchKeyword': search_keyword,
                    'validItemsCount': valid_count
                })
            except Exception as e:
                logging.error(f"ìƒí’ˆ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({product_name}): {str(e)}")
                results.append({
                    'productName': product_name,
                    'currentPrice': current_price,
                    'newPrice': current_price,
                    'priceDiff': 0,
                    'cardType': 'ì˜¤ë¥˜',
                    'filterInfo': 'ì²˜ë¦¬ì‹¤íŒ¨',
                    'searchKeyword': 'ì²˜ë¦¬ì‹¤íŒ¨',
                    'validItemsCount': 0,
                    'error': str(e)
                })
        
        # ì™„ë£Œ ë¡œê·¸
        logging.info("\n" + "=" * 80)
        logging.info("âœ… ì¹´ë“œ ìµœì €ê°€ ê²€ìƒ‰ ì™„ë£Œ")
        logging.info("=" * 80)
        changed_count = sum(1 for r in results if r['priceDiff'] != 0)
        logging.info(f"ì´ {len(results)}ê°œ ìƒí’ˆ ì²˜ë¦¬ ì™„ë£Œ")
        logging.info(f"ê°€ê²© ë³€ê²½: {changed_count}ê°œ")
        logging.info(f"ë³€ê²½ ì—†ìŒ: {len(results) - changed_count}ê°œ\n")
        
        return Response({
            'results': results,
            'totalProcessed': len(results)
        }, status=status.HTTP_200_OK)
        
    except Exception as e:
        logging.error(f"ê°€ê²© ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return Response({'error': f'Failed to search prices: {str(e)}'}, 
                       status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@csrf_exempt
@require_http_methods(["POST"])
def download_excel(request):
    """
    Download modified Excel file with updated prices and stock
    ì¶”ê°€ ì •ë³´: A~Fì—´ì— ë³€ë™ì•¡, ê¸°ì¡´ê°€ê²©, ì¹´ë“œíƒ€ì…, í•„í„°ì ìš©, ê²€ìƒ‰ê°œìˆ˜, ê²€ìƒ‰ì–´ ì¶”ê°€
    ê°€ê²© ë³€ë™ì— ë”°ë¼ ìƒ‰ìƒ ì ìš©
    
    Request body (JSON):
    {
        "modifications": [
            {
                "excelRow": int,
                "price": float,
                "stock": int,
                "productName": "string" (optional, for logging)
            },
            ...
        ]
    }
    
    File upload (multipart/form-data):
    - "excel_file": Excel file (.xlsx)
    """
    temp_file_path = None
    output_temp_path = None
    
    try:
        # 1. ë¡œê¹… ì„¤ì •
        logger.info("=" * 50)
        logger.info("Excel íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
        logger.info("=" * 50)
        
        # 2. ìš”ì²­ ë°ì´í„° íŒŒì‹±
        if 'excel_file' not in request.FILES:
            return JsonResponse({'error': 'íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, status=400)
        
        excel_file = request.FILES['excel_file']
        original_filename = excel_file.name
        logger.info(f"ì—…ë¡œë“œëœ íŒŒì¼: {original_filename}")
        logger.info(f"íŒŒì¼ í¬ê¸°: {excel_file.size} bytes")
        
        # modifications ë°ì´í„° íŒŒì‹±
        try:
            modifications_json = request.POST.get('modifications')
            if not modifications_json:
                return JsonResponse({'error': 'modifications ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}, status=400)
            
            modifications = json.loads(modifications_json)
            logger.info(f"ìˆ˜ì • í•­ëª© ê°œìˆ˜: {len(modifications)}")
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return JsonResponse({'error': 'modifications JSON íŒŒì‹± ì‹¤íŒ¨'}, status=400)
        
        # 3. ì„ì‹œ íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_file:
            temp_file_path = temp_file.name
            for chunk in excel_file.chunks():
                temp_file.write(chunk)
        
        logger.info(f"ì„ì‹œ íŒŒì¼ ìƒì„±: {temp_file_path}")
        
        # 4. ì—‘ì…€ íŒŒì¼ ë¡œë“œ
        try:
            workbook = openpyxl.load_workbook(temp_file_path)
            worksheet = workbook.worksheets[0]
            logger.info(f"ì›Œí¬ë¶ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            logger.error(f"ì›Œí¬ë¶ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise e
        
        # 5. ê¸°ì¡´ ì›Œí¬ì‹œíŠ¸ë¥¼ ì½ì–´ì„œ ìƒˆ ì›Œí¬ë¶ì— A~Fì—´ ì¶”ê°€í•˜ì—¬ ì¬êµ¬ì„±
        new_workbook = openpyxl.Workbook()
        new_worksheet = new_workbook.active
        
        logger.info("=" * 30)
        logger.info("ìƒˆ ì›Œí¬ì‹œíŠ¸ ìƒì„± - A~Fì—´ ì¶”ê°€")
        logger.info("=" * 30)
        
        # 6. modificationsë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•´)
        mod_dict = {int(mod['excelRow']): mod for mod in modifications}
        
        # 7. ëª¨ë“  í–‰ ì²˜ë¦¬
        for row_idx, row in enumerate(worksheet.iter_rows(), 1):
            new_row = []
            price_info = None
            
            # ì²« ë²ˆì§¸ í–‰ (í—¤ë”)
            if row_idx == 1:
                new_row.extend(["ë³€ë™ì•¡", "ê¸°ì¡´ê°€ê²©", "ì¹´ë“œíƒ€ì…", "í•„í„°ì ìš©", "ê²€ìƒ‰ê°œìˆ˜", "ê²€ìƒ‰ì–´"])
                # ê¸°ì¡´ ë°ì´í„° ì¶”ê°€
                for cell in row:
                    new_row.append(cell.value)
            else:
                # ë°ì´í„° í–‰ - ê¸°ë³¸ê°’ ì„¤ì •
                new_row.extend([0, 0, "", "", 0, ""])
                
                # ìˆ˜ì • ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                if row_idx in mod_dict:
                    mod = mod_dict[row_idx]
                    product_name = mod.get('productName', '')
                    
                    # Dì—´(ìƒí’ˆëª…)ì—ì„œ ì›ë³¸ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
                    original_price_cell = worksheet.cell(row=row_idx, column=6)  # Fì—´
                    original_price = float(original_price_cell.value) if original_price_cell.value else 0
                    new_price = float(mod.get('price', original_price))
                    price_diff = int(new_price - original_price)
                    
                    # ì¹´ë“œ ì •ë³´ ì¶”ì¶œ (ìµœì €ê°€ ê²€ìƒ‰ ì‹œ ì €ì¥ëœ ì •ë³´)
                    search_name, card_type, pokemon_info = CardGamePatternExtractor.extract_search_info(product_name)
                    
                    # A~Fì—´ ì •ë³´ ì„¤ì •
                    new_row[0] = price_diff  # ë³€ë™ì•¡
                    new_row[1] = int(original_price)  # ê¸°ì¡´ê°€ê²©
                    new_row[2] = card_type or "ë¯¸í™•ì¸"  # ì¹´ë“œíƒ€ì…
                    new_row[3] = mod.get('filterInfo', "")  # í•„í„°ì ìš© (í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬)
                    new_row[4] = mod.get('validCount', 0)  # ê²€ìƒ‰ê°œìˆ˜ (í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬)
                    new_row[5] = search_name or ""  # ê²€ìƒ‰ì–´
                    
                    price_info = (original_price, new_price)
                    
                    logger.info(f"í–‰ {row_idx}: {product_name} | {int(original_price)} â†’ {int(new_price)} ({price_diff:+}ì›)")
                
                # ê¸°ì¡´ ë°ì´í„° ë³µì‚¬
                for cell in row:
                    # Fì—´(ê°€ê²©) ë˜ëŠ” Hì—´(ì¬ê³ )ì´ê³  ìˆ˜ì • ì •ë³´ê°€ ìˆìœ¼ë©´ ìƒˆ ê°’ ì‚¬ìš©
                    if row_idx in mod_dict:
                        mod = mod_dict[row_idx]
                        if cell.column == 6:  # Fì—´ (ê°€ê²©)
                            new_row.append(float(mod.get('price', cell.value or 0)))
                        elif cell.column == 8:  # Hì—´ (ì¬ê³ )
                            new_row.append(int(float(mod.get('stock', cell.value or 0))))
                        else:
                            new_row.append(cell.value)
                    else:
                        new_row.append(cell.value)
            
            # ìƒˆ ì›Œí¬ì‹œíŠ¸ì— í–‰ ì¶”ê°€
            new_worksheet.append(new_row)
            
            # ê°€ê²© ì…€ì— ìƒ‰ìƒ ì ìš© (A~F 6ê°œ ì»¬ëŸ¼ ì¶”ê°€ë˜ì–´ Fì—´ì´ 12ì—´ë¡œ ì´ë™)
            if price_info is not None and row_idx > 1:
                price_cell = new_worksheet.cell(row=row_idx, column=12)  # Fì—´ì´ 12ì—´ë¡œ ì´ë™
                fill_color = PriceProcessor.get_fill_color(price_info[0], price_info[1])
                price_cell.fill = fill_color
        
        # 8. ìƒ‰ìƒ ë²”ë¡€ ì¶”ê°€ (ì²« ë²ˆì§¸ ì—´ì˜ 2~5í–‰)
        color_legend = [
            ("ì´ˆë¡ìƒ‰", "1000ì› ì´í•˜", COLOR_FILLS['green']),
            ("íŒŒë‘ìƒ‰", "2000ì› ì´í•˜", COLOR_FILLS['blue']),
            ("ë…¸ë‘ìƒ‰", "3000ì› ì´í•˜", COLOR_FILLS['yellow']),
            ("ë¹¨ê°•ìƒ‰", "3000ì› ì´ˆê³¼", COLOR_FILLS['red'])
        ]
        
        for i, (color_name, range_text, fill_color) in enumerate(color_legend, 2):
            new_worksheet.cell(row=i, column=1, value=color_name).fill = fill_color
            new_worksheet.cell(row=i, column=2, value=range_text)
        
        logger.info("ìƒ‰ìƒ ë²”ë¡€ ì¶”ê°€ ì™„ë£Œ")
        
        # 9. íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as output_temp:
            output_temp_path = output_temp.name
        
        try:
            new_workbook.save(output_temp_path)
            logger.info("ìƒˆ ì›Œí¬ë¶ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì›Œí¬ë¶ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            raise e
        finally:
            new_workbook.close()
            workbook.close()
        
        # 10. ì €ì¥ëœ íŒŒì¼ ê²€ì¦
        output_size = os.path.getsize(output_temp_path)
        logger.info(f"ì €ì¥ëœ íŒŒì¼ í¬ê¸°: {output_size} bytes")
        
        if output_size == 0:
            raise Exception("ì €ì¥ëœ íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤")
        
        # 11. HTTP ì‘ë‹µ ìƒì„±
        with open(output_temp_path, 'rb') as f:
            file_content = f.read()
        
        base_name = original_filename.rsplit('.', 1)[0] if '.' in original_filename else original_filename
        new_filename = f"{base_name}_ìˆ˜ì •.xlsx"
        
        response = HttpResponse(
            file_content,
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        response['Content-Disposition'] = f'attachment; filename="{new_filename}"'
        response['Content-Length'] = len(file_content)
        
        logger.info("=" * 50)
        logger.info("Excel íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
        logger.info("=" * 50)
        logger.info(f"íŒŒì¼ëª…: {new_filename}")
        logger.info(f"ì‘ë‹µ í¬ê¸°: {len(file_content)} bytes")
        logger.info(f"\nì¶”ê°€ëœ ì •ë³´:")
        logger.info(f"   Aì—´: ë³€ë™ì•¡ (ì •ìˆ˜)")
        logger.info(f"   Bì—´: ê¸°ì¡´ê°€ê²©")
        logger.info(f"   Cì—´: ì¹´ë“œ íƒ€ì…")
        logger.info(f"   Dì—´: í•„í„° ì ìš© ì—¬ë¶€")
        logger.info(f"        - ì›í”¼ìŠ¤: ì¼ë°˜ê²€ìƒ‰/íŒ¨ëŸ¬ë ê²€ìƒ‰/ìŠ¤í˜ì…œê²€ìƒ‰/ìŠˆí¼íŒ¨ëŸ¬ë (ë§ê°€)ê²€ìƒ‰")
        logger.info(f"        - ë””ì§€ëª¬: ì¼ë°˜ê²€ìƒ‰/í¬ì†Œê²€ìƒ‰/íŒ¨ëŸ¬ë ê²€ìƒ‰")
        logger.info(f"        - í¬ì¼“ëª¬: í¬ì¼“ëª¬ëª…ë§Œ/í¬ì¼“ëª¬ëª…+ë ˆì–´ë„/ë ˆì–´ë„ë§Œ/í•„í„°ì—†ìŒ")
        logger.info(f"   Eì—´: ê²€ìƒ‰ëœ ìƒí’ˆ ê°œìˆ˜")
        logger.info(f"   Fì—´: ê²€ìƒ‰ì–´")
        
        return response
        
    except Exception as e:
        logger.error("=" * 50)
        logger.error("ì „ì²´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        logger.error("=" * 50)
        logger.error(f"ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        return JsonResponse({'error': f'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)
        
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for file_path, desc in [(temp_file_path, "ì…ë ¥"), (output_temp_path, "ì¶œë ¥")]:
            if file_path and os.path.exists(file_path):
                try:
                    os.unlink(file_path)
                    logger.info(f"{desc} ì„ì‹œ íŒŒì¼ ì‚­ì œ: {file_path}")
                except Exception as e:
                    logger.warning(f"{desc} ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")